{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPS Probe mapping for many .csv input files in  <raw_dir> within the date range <start_date>  and <end_date>. \n",
    "### The csv file names must indicate the dates.\n",
    "### For working with single input file use gpsProbeMatching.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from datetime import datetime ,date\n",
    "\n",
    "import sys,os\n",
    "sys.path.append('py/') \n",
    "\n",
    "import shutil\n",
    "from functions import initialize, get_points_within_target_region, df2gdf, plot_map, check_dir, check_dir, get_all_files_from_dir\n",
    "from preprocess import preprocess_data\n",
    "from map_matching import map_match_csv2gpx, map_match_csv2gpx_multithread\n",
    "from generate_route_by_pyroutelib import generate_osm_routes_main\n",
    "from config import max_threads, OUTPUT_DIR, INPUT_DIR, map_matched_gps_probe\n",
    "\n",
    "from get_raw_files import get_raw_files_main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Input and Output locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dir = '/home/bidur/map_match_gps_data/raw_phl'\n",
    "mapmatching_input_dir = '/home/bidur/map_match_gps_data/raw_phl/phl_sample_clean/'\n",
    "backup_dir ='/home/bidur/map_match_gps_data/raw_phl/bak/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV prepare for input to  map-matching\n",
    "__Assumptions:__\n",
    "- start_date < end_date\n",
    "- raw input files are named with date in __yyyymmdd__ format. Ex. __NPL_data_20190404.csv__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- original csv files from *raw_dir* contains many fields.\n",
    "- Interesting fields in each csv are got via: \n",
    "         cut -d ',' -f 1,2,3,4,6,7,8,9 NPL_data_20190404.csv >  NPL_20190704.csv\n",
    "- timestamp field is creadted by joining different fileds using *py/get_raw_files.py*\n",
    "    - csv files with desired fields *(ap_id, timestamp, latitude, longitude)* are saved at : *mapmatching_input_dir*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Files from __raw_dir__ are processed and saved in __mapmatching_input_dir__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The following files are prepared: \n",
      "csv preparation for map-matching input complete\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#raw_dir = '/mnt/lv/heromiya/PHLMobilityData/'    ## original raw file location\n",
    "#mapmatching_input_dir = '/mnt/lv/bidur/PHL_raw_data/clean_input/test/' ## prepare csv in required format(ap_id, ) for map-matching\n",
    "\n",
    "\n",
    "start_date = date(2019, 4, 4) # NPL_data_20190404.csv\n",
    "end_date = date(2019, 4, 8)\n",
    "    \n",
    "get_raw_files_main(raw_dir, mapmatching_input_dir, start_date , end_date)    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "csv from __mapmatching_input_dir__ are processed and final csv are saved in __backup_dir__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/bidur/map_match_gps_data/raw_phl/2file.csv']\n",
      "/home/bidur/map_match_gps_data/raw_phl/2file.csv START  2020-11-16 09:58:33.708343\n",
      "6443 JUMP >  threshold(km/hr): 100 time taken(hr): 0.0011111111111111111  dist_covered: 0.35807186207479186\n",
      "ap_id (all): 2  ap_id (No JUMPS): 1\n",
      "\n",
      "completed:  java -jar matching-web/target/graphhopper-map-matching-web-1.0-SNAPSHOT.jar import map-data/philippines-latest.osm.pbf\n",
      "<< multithreaded_process() -> START 2020-11-16 09:59:52.170761\n",
      "Route Points cannot be generated as all the selected ap_id's have very few input data points\n",
      "\n",
      "\n",
      "PLEASE PROVIDE NEW INPUT WITH SUFFICIENT DATA \n",
      "\n",
      "\n",
      "1  csv file prepared and saved in  /home/bidur/map_match_gps_data/input/csv/1\n",
      "< apply_map_matching_multithread() >\n",
      "Current Working Directory  /home/bidur/map_match_gps_data/map-matching-master\n",
      "GPX_DIR:  /home/bidur/map_match_gps_data/map-matching-master/matching-web/src/test/resources/target/1\n",
      "\n",
      " Thread #1 completed:  java -jar matching-web/target/graphhopper-map-matching-web-1.0-SNAPSHOT.jar match /home/bidur/map_match_gps_data/map-matching-master/matching-web/src/test/resources/target/1/*.gpx\n",
      "\n",
      "convert_resgpx2csv -> /home/bidur/map_match_gps_data/output/res_csv/1\n",
      "Matched gpx -> /home/bidur/map_match_gps_data/map-matching-master/matching-web/src/test/resources/target/1/*.res.gpx\n",
      "Thread operation  complete\n",
      "\n",
      "\n",
      " Map Matching and route generation completed\n",
      "/home/bidur/map_match_gps_data/output/5_final_csv_4_mobmap.csv\n",
      "<< multithreaded_process() -> END 2020-11-16 09:59:53.874095\n",
      "/home/bidur/map_match_gps_data/raw_phl/2file.csv END  2020-11-16 09:59:53.874694\n",
      "Saved at:  /home/bidur/map_match_gps_data/raw_phl/bak/2file.csv\n",
      "__________________________________________________________________\n",
      "ALL TASK COMPLETED!!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#arr_input_csv = get_all_files_from_dir(mapmatching_input_dir)\n",
    "arr_input_csv= [\n",
    "    '/home/bidur/map_match_gps_data/raw_phl/2file.csv'\n",
    "                #'/home/bidur/map_match_gps_data/raw_phl/2222.csv',\n",
    "               # '/home/bidur/map_match_gps_data/raw_phl/1643_1.csv'\n",
    "               ]\n",
    "print(arr_input_csv)\n",
    "for gps_csv in arr_input_csv:\n",
    "      \n",
    "    '''\n",
    "    if '20190203' in gps_csv:\n",
    "        continue\n",
    "    '''\n",
    "    \n",
    "    print(gps_csv, 'START ', str( datetime.now() ))\n",
    " \n",
    "    # 1. remove old data and create necessary directories\n",
    "    initialize()\n",
    "\n",
    "    # 2. ananymize ap_id column to int value ,   clip points within boundary\n",
    "    gdf_probe_clipped, gdf_target = get_points_within_target_region (gps_csv, anonymize=False, display_plot = False)\n",
    "    #gdf_probe_clipped, gdf_target = get_points_within_target_region (gps_csv, anonymize=True, display_plot = False)\n",
    "    \n",
    "    #print('----2 done----')\n",
    "    \n",
    "    \n",
    "    # 3. Preprocess: cleaning data & applying sampling\n",
    "    df_sample = preprocess_data()\n",
    "    #print('----3 done----')\n",
    "\n",
    "    # 4. map matching with osm roads using graphhopper\n",
    "    df_mapped_route = map_match_csv2gpx_multithread(df_sample) # multithreaded\n",
    "    \n",
    "    #Use this for normal execution without multi thread ( IF user permission do not allow multi-threading):\n",
    "    #df_mapped_route = map_match_csv2gpx(df_sample)\n",
    "    #print('----4 done----')\n",
    "    \n",
    "        \n",
    "    # 5. save final csv to backup dir\n",
    "    check_dir(backup_dir)# create directory if not exit\n",
    "    csv_path, csv_name = os.path.split(gps_csv)\n",
    "    final_data_path = backup_dir+csv_name\n",
    "    shutil.copyfile(map_matched_gps_probe,final_data_path)\n",
    "    \n",
    "    print(gps_csv, 'END ', str( datetime.now() ))\n",
    "    print('Saved at: ', final_data_path)\n",
    "    print('__________________________________________________________________')\n",
    "    \n",
    "\n",
    "print(\"ALL TASK COMPLETED!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No traceback available to show.\n"
     ]
    }
   ],
   "source": [
    "%tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Output summary for a sample inout for 20190703\n",
    "- about 9 hr 30 min \n",
    "- 10% = 525 ap_ids\n",
    "- 411 ap_ids in final output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
